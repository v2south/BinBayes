{"name":"A Bayesian Approach to Logistic/Probit Mixed Effects Analysis of Repeated Measures Accuracy Studies","tagline":"Yin Song, Farouk Nathoo, Michael E. J. Masson ","body":"# BinBayes.R\r\n\r\nBinBayes.R is the software implementation of Bayesian approach for the mixed effects analysis of accuracy studies using mixed binomial regression models. \r\n\r\n## Introduction \r\n\r\nWe assume that the user has both the [<strong>R</strong>](https://cran.r-project.org/mirrors.html) and [<strong>JAGS</strong>](http://mcmc-jags.sourceforge.net/) software packages installed and is familiar with the basic structure and syntax of the R language. In addition, we also require following three R packages: [<strong>coda</strong>](https://cran.r-project.org/web/packages/coda/index.html),[ <strong>lme4</strong>](https://cran.r-project.org/web/packages/lme4/index.html) and \r\n[<strong>rjags</strong>](https://cran.r-project.org/web/packages/rjags/index.html). \r\nTo install these R packages, please see this [manual](https://cran.r-project.org/doc/manuals/r-release/R-admin.html#Installing-packages) from CRAN. \r\n\r\nThe R function BinBayes.R requires four input variables as follows:\r\n\r\n* <strong> m_data </strong> is a matrix or data frame containing the data from your study. This data frame should have four columns. The first column contains the subject identifier; the second column contains the item identifier; the third column contains the identifier for experimental condition; the fourth column holds a binary valued accuracy response. These columns should be listed in the order of *subject*, *item number*, *condition*, *accuracy* respectively.\r\n\r\n* <strong>link</strong> is a string that specifies the link function as ”Logit” or ”Probit”.\r\n* <strong> model </strong>  is a string taking five possible values as follows:\r\n  * \"M1\", baseline model with random subject and item effects with no effect of experimental condition.\r\n  * \"M2\", model with random subject and item effects and with a fixed effect for the experimental condition.\r\n  * \"M3\", model with random subject and item effects and where the effect of experimental condition varies across subjects.\r\n  * \"M4\", model with random subject and item effects and where the effect of experimental condition varies across items.\r\n  * \"M5\", model with random subject and item effects and where the effect of experimental condition varies across both subjects and items.\r\n* <strong>baseline</strong> is a string that specifies the baseline condition. It will automatically pick one condition as baseline if no specific condition is given.\r\n\r\n\r\nAs illustrated below, the output of the BinBayes.R function will consist of an object having five components with the following names:\r\n\r\n* <strong>bic</strong> is the value of the BIC for the fitted model.\r\n* <strong>waic</strong>  is the value of the WAIC for the fitted model.\r\n* <strong>post_summary</strong> is an mcmc list containing samples from the posterior distribution for all components of the fitted model.\r\n* <strong>condition_level</strong> is the ordered condition level in the model. The first level would be the baseline.\r\n* <strong>baseline</strong> is the baseline condition.\r\n\r\nWe will illustrate how to use BinBayes.R in the following two examples. Download BinBayes.R from [here](https://raw.githubusercontent.com/v2south/BinBayes/master/R_script/BinBayes.R)\r\n\r\n\r\n## Example 1\r\n\r\n\r\nFor this example, We were investigating the development of memory for visual scenes that occurs when one searches a scene for a particular object. We were specifically interested in what subjects might learn about other, non-target objects present in the scene while searching for the target object. In the first phase of the experiment, subject searched 80 scenes for a particular target object. In the test phase, they again searched the 80 scenes from the study phase as well as a set of 40 new scenes (new condition), looking for a specific target object in each case. For 40 of the scenes that had appeared in the first phase of the experiment, the target object was the same as in the first phase (studied condition), and for the other 40 scenes a new target was designated (alternate condition). In all 120 of these critical scenes, the target was present in the scene. Accuracy reflects whether or not the target was detected in the scene. Our primary interest was in whether there would be a benefit in the alternate condition, relative to the new condition, for having previously searched the scene (albeit for a different target). So the independent variable was scene type (studied, alternate, new) and the dependent variable was successful or failed detection of the target. There was also an additional set of scenes that did not contain the target that subjects were asked to search for, just to ensure that the task would be meaningful. Performance with these items was not analyzed. Dataset for this example could be downloaded from [here](https://github.com/v2south/BinBayes/blob/master/dataset/Scenes3_Bayesian.txt) and it has:\r\n\r\n *\t30 subjects\r\n *\t3 conditions\r\n *\t240 items\r\n *\t3550 total observations\r\n *\tOverall accuracy 89.8%\r\n \r\nTo get started, Let's download the BinBaye.R and save it in the same directory or folder with dataset Scenes3_Bayesian.txt.\r\n\r\n```\r\n# Path is the file directory where you save the BinBayes.R and dataset Prime3_Bayesian.txt should be in the same directory\r\n > path <- \"/Users/Yin/Dropbox/BinBayes/BinBayes.R\"\r\n\r\n # Load BinBayes.R\r\n > source(path)\r\n \r\n# Read data into R\r\n> accuracy <- read.table(\"/Users/Yin/Dropbox/BinBayes/Scenes3_Bayesian.txt\", header=TRUE, na.strings='.',colClasses=c('factor','factor','factor','numeric'))\r\n> #remove cases with missing values\r\n> accuracy<-na.omit(accuracy)\r\n> accuracy\r\n     subj itemID cond Acc\r\n1     s01   i001  std   1\r\n2     s01   i004  alt   1\r\n3     s01   i006  new   1\r\n4     s01   i008  new   1\r\n5     s01   i009  std   1\r\n6     s01   i011  alt   1\r\n7     s01   i014  new   1\r\n8     s01   i016  new   1\r\n9     s01   i017  std   1\r\n10    s01   i020  std   1\r\n11    s01   i022  std   0\r\n12    s01   i024  std   1\r\n13    s01   i026  new   1\r\n14    s01   i027  new   1\r\n15    s01   i029  std   1\r\n16    s01   i032  std   1\r\n17    s01   i034  alt   1\r\n18    s01   i035  new   1\r\n19    s01   i038  alt   1\r\n20    s01   i039  std   1\r\n21    s01   i042  std   1\r\n.\r\n.\r\n.\r\n.\r\n```\r\nSuppose we are interested in comparing model 1 and model 2 with logit link function, We can first compute BIC and WAIC for both models. \r\n\r\n```\r\n\r\n# Model 1 with Logit link\r\n> L1_result <- BinBayes(accuracy, \"M1\", \"Logit\")\r\nLoading required package: Matrix\r\nLinked to JAGS 3.4.0\r\nLoaded modules: basemod,bugs\r\n  |++++++++++++++++++++++++++++++++++++++++++++++++++| 100%\r\n  |**************************************************| 100%\r\n  |**************************************************| 100%\r\n  |**************************************************| 100%\r\n\r\n> L1_result$bic\r\n[1] 2049.508\r\n> L1_result$waic\r\n[1] 1880.468\r\n> L1_result$baseline\r\n[1] std\r\nLevels: alt new std\r\n> L1_result$condition_level\r\n[1] std alt new\r\nLevels: alt new std\r\n\r\n\r\n# Model 2 with Logit link\r\n> L2_result <- BinBayes(accuracy, \"M2\", \"Logit\")\r\n> L2_result$bic\r\n[1] 2020.746\r\n> L2_result$waic\r\n[1] 1835.745\r\n> L2_result$baseline\r\n[1] std\r\nLevels: alt new std\r\n> L2_result$condition_level\r\n[1] std alt new\r\nLevels: alt new std\r\n```\r\n\r\nAccording to the BIC and WAIC values, we can see that model 2 with random effects for subject and item and a fixed effect for condition is optimal among the these two models. Then we can get posterior summary from model 2 by <strong> *summary()*</strong> function.\r\n\r\n```\r\n> summary(L2_result$post_summary)\r\n\r\nIterations = 12001:32000\r\nThinning interval = 1 \r\nNumber of chains = 1 \r\nSample size per chain = 20000 \r\n\r\n1. Empirical mean and standard deviation for each variable,\r\n   plus standard error of the mean:\r\n\r\n             Mean     SD  Naive SE Time-series SE\r\na[1]     -0.11448 0.9904 0.0070032       0.009571\r\na[2]     -0.85242 0.8024 0.0056739       0.007862\r\na[3]      0.10590 0.9522 0.0067328       0.009261\r\na[4]      0.09433 0.9397 0.0066448       0.008666\r\na[5]      1.05577 1.2407 0.0087731       0.011628\r\na[6]     -0.04343 0.9677 0.0068425       0.009498\r\na[7]      1.23382 1.1968 0.0084630       0.011032\r\na[8]      0.10627 0.9540 0.0067461       0.009359\r\na[9]      1.06573 1.2328 0.0087172       0.011379\r\na[10]    -2.55822 0.5976 0.0042253       0.007460\r\na[11]    -2.24377 0.6107 0.0043181       0.007147\r\na[12]    -0.14575 0.9604 0.0067909       0.009049\r\n.\r\n.\r\n.\r\n\r\nalpha[1]  0.00000 0.0000 0.0000000       0.000000  # Condition std\r\nalpha[2] -0.90427 0.1715 0.0012128       0.003857  # Condition alt\r\nalpha[3] -1.02556 0.1696 0.0011992       0.003634  # Condition new\r\n.\r\n.\r\n.\r\nb[27]    -0.30396 0.3240 0.0022910       0.004301\r\nb[28]     0.76835 0.3971 0.0028078       0.004777\r\nb[29]     0.35706 0.3825 0.0027050       0.004741\r\nb[30]    -0.03684 0.3441 0.0024334       0.004709\r\nbeta0     3.84647 0.2384 0.0016859       0.009772\r\nsigma_a   1.64579 0.1410 0.0009969       0.003578\r\nsigma_b   0.70411 0.1253 0.0008858       0.001730\r\n\r\n```\r\nThe notations for each model component are:\r\n\r\n<center>\r\n\r\n| Model Component |                           Explanation                           |\r\n|:---------------:|:---------------------------------------------------------------:|\r\n|     alpha[i]    |                  Fixed Effect from Condition[i]                 |\r\n|       a[j]      |                    Random Effect from Item[j]                   |\r\n|       b[k]      |                  Random Effect from Subject[k]                  |\r\n|      beta0      |                         Model Intercept                         |\r\n|     sigma_a     |            Standard Deviation for Random Item Effect            |\r\n|     sigma_b     |           Standard Deviation for Random Subject Effect          |\r\n\r\n</center>\r\n\r\n\r\nAlso, notice that baseline condition is <em>std</em> for both models since we didn't specify the baseline condition at beginning. We can also set the baseline to <em>new</em> as:\r\n\r\n```\r\n> L2_new_result <- BinBayes(accuracy, \"M2\", \"Logit\",\"new\")\r\n> L2_new_result$bic\r\n[1] 2020.746\r\n> L2_new_result$waic\r\n[1] 1836.863\r\n> L2_new_result$condition_level\r\n[1] new alt std\r\nLevels: alt new std\r\n> L2_new_result$baseline\r\n[1] \"new\"\r\n\r\n```\r\nSince the baseline condition is <em> new </em> now, the posterior summary for condition would also change as:\r\n\r\n```\r\n> summary(L2_new_result$poster_distribution)\r\n\r\nIterations = 12001:32000\r\nThinning interval = 1 \r\nNumber of chains = 1 \r\nSample size per chain = 20000 \r\n\r\n1. Empirical mean and standard deviation for each variable,\r\n   plus standard error of the mean:\r\n\r\n               Mean     SD  Naive SE Time-series SE\r\na[1]     -0.1381526 0.9597 0.0067864       0.009222\r\na[2]     -0.8483886 0.8117 0.0057399       0.008231\r\na[3]      0.1075865 0.9414 0.0066567       0.009286\r\na[4]      0.1155041 0.9463 0.0066913       0.009295\r\na[5]      1.0501409 1.2452 0.0088046       0.011279\r\na[6]     -0.0396419 0.9529 0.0067377       0.009271\r\na[7]      1.2152686 1.1842 0.0083734       0.011406\r\na[8]      0.1136061 0.9329 0.0065968       0.008816\r\na[9]      1.0356179 1.2262 0.0086704       0.011805\r\na[10]    -2.5505333 0.5896 0.0041692       0.007777\r\na[11]    -2.2260440 0.6115 0.0043236       0.007669\r\na[12]    -0.1168826 0.9798 0.0069280       0.009170\r\na[13]     1.2305091 1.2001 0.0084860       0.011587\r\na[14]     1.1816613 1.1963 0.0084591       0.011595\r\na[15]     1.0547813 1.2524 0.0088561       0.011643\r\na[16]     1.0478054 1.2214 0.0086366       0.011347\r\na[17]     1.1015207 1.2190 0.0086196       0.011925\r\na[18]    -1.9143807 0.6066 0.0042894       0.007095\r\na[19]     1.1166556 1.2123 0.0085726       0.011444\r\n.\r\n.\r\n.\r\nalpha[1]  0.0000000 0.0000 0.0000000       0.000000 # Condition new\r\nalpha[2]  0.1209206 0.1464 0.0010351       0.002333 # Condition alt\r\nalpha[3]  1.0376313 0.1717 0.0012139       0.002484 # Condition std\r\n.\r\n.\r\n.\r\nb[26]     0.5135574 0.3734 0.0026405       0.004417\r\nb[27]    -0.2997185 0.3208 0.0022685       0.004270\r\nb[28]     0.7657723 0.3889 0.0027497       0.004230\r\nb[29]     0.3713921 0.3710 0.0026231       0.004368\r\nb[30]    -0.0254439 0.3396 0.0024011       0.004399\r\nbeta0     2.7935181 0.2134 0.0015088       0.007985\r\nsigma_a   1.6323807 0.1407 0.0009952       0.003600\r\nsigma_b   0.7007261 0.1246 0.0008812       0.001655\r\n\r\n```\r\n\r\n\r\n\r\n## Example 2\r\n\r\nFor this example, we were investigating the influence of a semantic context on the identification of printed words shown either under clear (high contrast) or degraded (low contrast) conditions. The semantic context consisted of a prime word presented in advance of the target item. On critical trials, the target item was a word and on other trials the target was a nonword. The task was to classify the target on each trial as a word or a nonword (this is called a \"lexical decision\" task). Our interest is confined to trials with word targets. The prime word was either semantically related or unrelated to the target word (e.g., granite-STONE vs. attack-FLOWER), and the target word was presented either in clear or degraded form. Combining these two factors produced four conditions (related-clear, unrelated-clear, related-degraded, unrelated-degraded). For the current analysis, accuracy of response was the dependent measure. Dataset for this example could be downloaded from [here](https://github.com/v2south/BinBayes/blob/master/dataset/Prime3_Bayesian.txt) and it has:\r\n\r\n *\t72 subjects\r\n *\t4 conditions\r\n *\t120 items\r\n *\t8640 total observations\r\n *\tOverall accuracy 95.4%\r\n\r\nTo get started, Let's download the BinBaye.R and save it in the same directory or folder with dataset Prime3_Bayesian.txt.\r\n\r\n```\r\n # Path is the file directory where you save the BinBayes.R and dataset Prime3_Bayesian.txt should be in the same directory\r\n > path <- \"/Users/Yin/Dropbox/BinBayes/BinBayes.R\"\r\n \r\n # Load BinBayes.R\r\n > source(path)\r\n \r\n # Read the data into R\r\n > accuracy <- read.table(\"/Users/Yin/Dropbox/BinBayes/Prime3_Bayesian.txt\",header=TRUE, na.strings=’.’, colClasses=c(’factor’,’factor’,’factor’,’numeric’))\r\n > accuracy\r\n     subj itemID cond Acc\r\n1     S01   i001   UD   1\r\n2     S01   i002   RD   1\r\n3     S01   i003   UC   1\r\n4     S01   i004   RD   1\r\n5     S01   i005   RD   1\r\n6     S01   i006   UC   1\r\n7     S01   i007   RD   1\r\n8     S01   i008   UD   1\r\n9     S01   i009   RC   1\r\n10    S01   i010   UD   1\r\n.\r\n.\r\n.\r\n\r\n```\r\n\r\nSuppose we are interested in comparing model 1, model 2 and model 4 with Logit as link function. We can compute the BIC and WAIC values as:\r\n\r\n```\r\n# Model 1 with Logit link\r\n\r\n> L1_result <- BinBayes(accuracy,\"M1\",\"Logit\")\r\n> L1_result$bic\r\n[1] 2927.731\r\n> L1_result$waic\r\n[1] 2826.157\r\n\r\n# Model 2 with Logit link\r\n\r\n\r\n\r\n # Model 4 with Logit link\r\n> L4_result <- BinBayes(accuracy, \"M4\", \"Logit\")\r\n\r\n> L4_result$bic\r\n[1] 2996.642\r\n\r\n> L4_result$waic\r\n[1] 2799.036\r\n\r\n \r\n \r\n```\r\n\r\n|          Model          |    BIC   | WAIC     |\r\n|:-----------------------:|:--------:|----------|\r\n| Model 1 with Logit Link | 2927.731 | 2826.157 |\r\n| Model 2 with Logit Link | <strong>2925.133</strong> | 2801.64  |\r\n| Model 4 with Logit Link | 2996.642 | <strong>2799.036</strong> |\r\n\r\n\r\nAccording to the BIC and WAIC values in the table above, we can see that model 4 has the lowest WAIC among these three models. We can then summarize the posterior distribution of L4 with <strong>*summary()*</strong> function as:\r\n\r\n```\r\n> summary(L4_result$post_summary)\r\n                       Mean         SD     Naive SE Time-series SE\r\na[1]           -1.651674140 0.38186812 0.0027002154    0.004879634\r\na[2]            1.029455547 0.76992876 0.0054442184    0.007200982\r\na[3]           -0.447599745 0.51547315 0.0036449456    0.005530853\r\na[4]            0.546810962 0.67984946 0.0048072617    0.006687512\r\na[5]            0.136480949 0.60239446 0.0042595721    0.005966830\r\na[6]            0.535923970 0.66998439 0.0047375051    0.006276845\r\na[7]            0.519061256 0.68674737 0.0048560372    0.006519361\r\na[8]           -0.467438591 0.51890334 0.0036692007    0.005693154\r\na[9]            0.523479478 0.67846659 0.0047974833    0.006230641\r\na[10]           1.035360069 0.77143129 0.0054548430    0.007454912\r\na[11]           1.049869155 0.76432484 0.0054045928    0.007214576 \r\n.\r\n.\r\n.\r\n.\r\nbeta0           3.217671589 0.15527295 0.0010979456    0.004889324\r\nsigma_a         1.042560073 0.10279647 0.0007268808    0.001817836\r\nsigma_alpha_a   0.317394541 0.14507561 0.0010258394    0.020849972\r\nsigma_b         0.443902891 0.08877508 0.0006277346    0.002598334\r\n\r\n2. Quantiles for each variable:\r\n\r\n                   2.5%       25%       50%       75%    97.5%\r\na[1]           -2.38914 -1.911754 -1.659339 -1.400410 -0.88743\r\na[2]           -0.34661  0.497792  0.975816  1.528980  2.64438\r\na[3]           -1.39199 -0.806694 -0.469248 -0.115705  0.60561\r\na[4]           -0.67710  0.069030  0.518771  0.983691  1.99242\r\na[5]           -0.95792 -0.286522  0.108670  0.525298  1.39232\r\na[6]           -0.66690  0.059904  0.502328  0.968129  1.95428\r\na[7]           -0.71599  0.040254  0.478461  0.961174  1.96379\r\na[8]           -1.42810 -0.827322 -0.484480 -0.131673  0.59941\r\na[9]           -0.69629  0.052312  0.487627  0.950006  1.95645\r\na[10]          -0.35858  0.494469  0.993932  1.532204  2.68696\r\na[11]          -0.31349  0.512905  1.005407  1.533181  2.68946\r\n.\r\n.\r\n.\r\nb[71]          -1.23225 -0.825627 -0.611229 -0.402596 -0.01648\r\nb[72]          -0.47808 -0.069099  0.146281  0.371175  0.84990\r\nbeta0           2.91566  3.111778  3.214427  3.322229  3.52518\r\nsigma_a         0.85684  0.970334  1.036779  1.107859  1.25747\r\nsigma_alpha_a   0.09272  0.199065  0.304277  0.418378  0.62032\r\nsigma_b         0.27230  0.384950  0.442368  0.501785  0.62098\r\n```\r\n\r\nThe notations for each model component are:\r\n\r\n<center>\r\n\r\n| Model Component |                           Explanation                           |\r\n|:---------------:|:---------------------------------------------------------------:|\r\n|     alpha[i]    |                  Fixed Effect from Condition[i]                 |\r\n|       a[j]      |                    Random Effect from Item[j]                   |\r\n|       b[k]      |                  Random Effect from Subject[k]                  |\r\n|      beta0      |                         Model Intercept                         |\r\n|  sigma_alpha_a  | Standard Deviation for Random Effect between Condition and Item |\r\n|     sigma_b     |           Standard Deviation for Random Subject Effect          |\r\n|     sigma_a     |            Standard Deviation for Random Item Effect            |\r\n\r\n</center>\r\n\r\nTo get the 95% HPD interval from posterior distribution, we can use the <strong>*HPDinterval()*</strong> function as:\r\n\r\n```\r\n> HPDinterval(L4_result$post_summary)\r\n[[1]]\r\n                   lower       upper\r\na[1]           -2.37513723 -0.876461878\r\na[2]           -0.42330027  2.542678120\r\na[3]           -1.45065339  0.535163576\r\na[4]           -0.71871493  1.922685809\r\n.\r\n.\r\n.\r\n.\r\n```\r\n\r\nTo create the density plots and boxplots summarizing the posterior distribution, in particular the condition effects, we can first use the <strong>*varnames()*</strong> function in R to see all the variable names in the post summary component of the fitted model. We then extract the corresponding variables to create posterior density plots and item effect boxplots for the parameters that we are interested in.\r\n\r\n\r\n```\r\n> varnames(L4_result$post_summary)\r\n[1] \"a[1]\"         \"a[2]\"         \"a[3]\"         \"a[4]\"         \"a[5]\"          \r\n[6] \"a[6]\"         \"a[7]\"         \"a[8]\"         \"a[9]\"         \"a[10]\"         \r\n.\r\n.\r\n.\r\n[671] \"b[67]\"      \"b[68]\"        \"b[69]\"        \"b[70]\"        \"b[71]\"         \r\n[676] \"b[72]\"      \"beta0\"        \"sigma_a\"      \"sigma_alpha_a\" \"sigma_b\"  \r\n```\r\n\r\nTo get the posterior density for \"sigma_a\", which is standard deviation for random item effect, we need to find the location of  \"sigma_a\" in this mcmc list which is in column 678. Then we can get:\r\n\r\n\r\n```\r\n> plot(L4_result$post_summary[,678])\r\n```\r\n\r\n\r\n![Posterior Plot](https://cloud.githubusercontent.com/assets/2337149/13296876/787467fa-dae4-11e5-9932-bea8a89596a1.png)\r\n\r\nTo create boxplots of condition effect by item, we can do as follows:\r\n\r\n \r\n 1. Get the ordered condition level from *condition_level*.\r\n 2. Reformat the *post\\_summary* part from result as a matrix by *as.matirx()* function.\r\n 3. Use *varnames()* function to locate the columns of fixed effect of condition and mix effect between item and condition for the specific condition.\r\n 4. Add the fixed condition effect to the corresponding mix effect columns.\r\n 5. Use *apply()* function to find the median of columns obtained in (3) and sort them by *order()* function.\r\n 6. Then use these ordered columns in (4) to create boxplot.\r\n\r\nWe select the second condition (RD) in the demonstration below:\r\n\r\n```\r\n> L4_result$baseline\r\n[1] UD\r\nLevels: RC RD UC UD\r\n\r\n> L4_result$condition_level\r\n[1] UD RD UC RC\r\nLevels: RC RD UC UD\r\n\r\n# Notice that RD is the second condition, we need to find the location of alpha[2] and all alpha_a[2,]s.\r\n# By observing from varnames() result, we can see that alpha[2] is on the 122 column and all alpha_a[2,]s is located from 126 to 604 by every 4 columns.\r\n# We have 120 items for each condition.\r\n\r\n> index <- seq(from=126, to=604, by=4)\r\n\r\n> rd_item <- as.matrix(M4_result$post_summary)[, index]\r\n\r\n> colnames(rd_item) <- seq(from=1,to=120)\r\n\r\n> # Fixed effect from second condition(RD)\r\n> alpha_2 <- as.matrix(M4_result$post_summary)[,122]\r\n> # Add the fixed effect to the mix effect\r\n\r\n> for(i in  1:120){\r\n+   rd_item[,i] <- rd_item[,i] + alpha_2\r\n+ }\r\n> # Sort the columns by median and get the index of sorted columns\r\n> t2 <- apply(rd_item,2, median)\r\n> order_index <- order(t2)\r\n\r\n> # Swap the columns and their column names\r\n> rd_item[,1:120] <- rd_item[,order_index]\r\n> colnames(rd_item) <- order_index\r\n> boxplot(rd_item,outline=FALSE,col=\"green\")\r\n> abline(h=0,col=\"red\")\r\n> title(main=\"RD effect by item\")\r\n```\r\n<img src=\"https://cloud.githubusercontent.com/assets/2337149/13300180/b19635fe-daf3-11e5-83e1-f1851c5bfacf.png\" width=\"800\">\r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}